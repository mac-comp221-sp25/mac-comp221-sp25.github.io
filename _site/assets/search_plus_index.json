{"/pages/2-5incident/": {
    "title": "Skiena Problem 2-5",
    "keywords": "Activity Sorting",
    "url": "/pages/2-5incident/",
    "body": "Let this be a reminder for me to pick less tricky problems. Given the number of mistakes I’ve made prepping and solving this live, here is my authoritative analysis of the time complexity of this algorithm. Lower bound I didn’t present this in class (maybe hinted at it in one of the sections?), but I’ll demonstrate how you can derive a lower bound! We showed in class that the print statement runs approximately (up to rounding errors) $\\sum_{k=1}^n (\\log(n/k))$ times. Here’s a trick: Since $\\log(x) \\geq 0$ for $x \\geq 1$, we know each term in this sum is positive. So by removing some of the terms, we only make the sum smaller! Let’s get rid of half of the terms, so \\[\\sum_{k=1}^n \\log(n/k) \\geq \\sum_{k=1}^{n/2} \\log(n/k)\\] Note that I’m assuming that $n$ is even and thus $n/2$ is an integer. You can convince yourself this won’t matter in the end! Now we should observe that the logarithm is an increasing function, which means that \\[\\sum_{k=1}^{n/2} \\log(n/k) \\geq \\sum_{k=1}^{n/2} \\log(n/(n/2))\\] I.e., we replace each of the terms in the sum with the smallest term to get a lower bound! But, that simplifies! \\[\\sum_{k=1}^{n/2} \\log(n/(n/2)) = \\sum_{k=1}^{n/2} \\log(2) = \\log(2)n/2\\] So, summing it all up (ha!), we find that our growth function is bounded from below by $(\\log(2)/2) n$, so with $c = \\log(2)/2$ and $n_0 &gt; 1$, we have that our function is $\\Omega(n)$. Upper bounds I’ll present 2 upper bounds. A looser upper bound that I showed in class, and a stricter upper bound that requires a trick I won’t expect you to know off the top of your head. In class, I demonstrated that the algorithm is $O(n\\log(n))$. We showed in class that the print statement runs approximately (up to rounding errors) $\\sum_{k=1}^n \\log(n) - \\sum_{k=1}^n \\log(k)$ times (we showed this is equivalent to what I claimed in the lower bound section in class!) Since $\\log(k) &gt; 0$ for $k &gt; 1$, and the index k counts up from 1, we know that $\\sum_{k=1}^n \\log(k)$ is positive! That lets us bound the runtime from above by the first term. That is \\[\\sum_{k=1}^n \\log(n) - \\sum_{k=1}^n \\log(k) \\leq \\sum_{k=1}^n \\log(n)\\] and since the $\\log(n)$ in the last term doesn’t care about the index $k$ of the summation, $\\sum_{k=1}^n \\log(n)$ is simply $n\\log(n)$. This is (silliness aside), the upper bound I showed in class, and the one I’ll expect you to be able to pull out at a moment’s notice. However, it turns out we can do better! Above, we had a really weak bound on $\\sum_{k=1}^n \\log(k)$ — just that it’s positive! But it turns out there’s a very fancy approximation of this value. Stirling’s Approximation tells us that $\\log(n!) = n\\log(n) - n\\log(e) + O(\\log(n))$, with that last term just indicated something of order $\\log(n)$. This may not seem like it applies, but… \\[\\sum_{k=1}^n \\log(k) = \\log(\\prod_k^n k) = \\log(n!)\\] Remember sums of logs are logs of products! So, we can reduce as follows: \\[\\begin{aligned} \\sum_{k=1}^n \\log(n) - \\sum_{k=1}^n \\log(k) &amp;= n\\log(n) - \\log(n!) \\\\ &amp;= n\\log(n) - n\\log(n) + \\log(e)n - O(log(n)) \\\\ &amp;= \\log(e)n - O(\\log(n)) \\end{aligned}\\] Which should clearly look $O(n)$ (note that n dominates anything $O(\\log(n)$, so picking $c\\geq log(e)$ will allow you to find some $n_0$ to satisfy the definition of $O(n)). The Theta Since we saw that the algorithm is both $O(n)$ and $\\Omega(n)$, it is $\\Theta(n)$ (by my definition! If you haven’t already, convince yourself that this is the same as the book’s big-$\\Theta$ analysis. In Summary I messed this up (my prep was lacking!), and so if Stirling’s Approximation ever comes up, I’ll be sure to give it to you. And I’ll try not to pick questions tricky enough to trick me. My bad, hope making you read more math helps!"
  },"/pages/Activity01/": {
    "title": "Activity 01: Sorting 1",
    "keywords": "Activity Sorting",
    "url": "/pages/Activity01/",
    "body": "Learning Goals You will work towards being able to… Formalize algorithmic ideas into pseudocode Compute growth functions from time &amp; space complexities under the RAM model Know common algorithms to solve cannonical problems (sorting) Instructions Look at the set of numbered index cards in front of you. They should start in the order [4 -12 6 3 1]. Have a volunteer at your table slowly and methodically demonstrate how they’d rearrange the cards so that they are in increasing order. If you’re the volunteer, do this in a way that seems natural to you (and perhaps not in an unintuitive way that might be slightly more efficient for a computer!). Formalize the mechanics of your table’s chosen sorting technique. Describe it as a combination of a few basic operations: comparisons, and swapping the positions of two numbers. Write out pseudocode to describe your sorting operation. Starting from the array listed in step 1, count the number of basic operations it takes to sort the array using your sorting algorithm. Now, consider how far from a best or worst case scenario the array you were given was. Try and see if you can can determine the worst-case input (of length 5!) for your sorting algorithm. If you think you’ve found the worst possible case, share your reasoning and try and convince your table-mates that no input would take any longer. How many time steps does your algorithm take in the worst case? Hint: Since all sorting cares about the relative ordering of elements, you only need to consider different initial shuffles of the 5 elements. If you have spare time, try: Do the above for a different intuitive sorting algorithm from someone else at the table. Are the worst-case arrays different for the two? Can you come up with a way to construct a worst-case array for your algorithm for any n? See if you can generalize a worst-case growth function for the time complexity of this algorithm. We’ve assumed that the only things you can do are compare and swap elements in the array. Would your algorithm be faster with access to a different data structure or basic operation? For credit: Submit the pseudocode of your algorithm to Moodle. If you found a worst-case input for your algorithm, provide that as well!"
  },"/pages/Activity02/": {
    "title": "Activity 02: Sorting 2",
    "keywords": "Activity Sorting",
    "url": "/pages/Activity02/",
    "body": "Learning Goals You will work towards being able to… Formalize algorithmic ideas into pseudocode Compute growth functions from time &amp; space complexities under the RAM model Determine the Big-O, big-$\\Omega$, and big-$\\Theta$ time complexities of algorithms Know common algorithms to solve cannonical problems (sorting) Instructions Look back at the pseudocode you’ve written for Activity 1 (check your Moodle submission) Determine an explicit growth function for your pseudocode’s worst-case time complexity. If the sort algorithm you found is suspiciously similar to insertion sort, take a moment to chat with an adjacent group and acquire a copy of their pseudocode Use your prior background from COMP128 to speculate about the big-Oh time complexity of your algorithm. Do people at the table agree? Formally demonstrate how your growth function fits that time-complexity. Consider both big-O and big-$\\Omega$ (and, thus, big-$\\Theta$). If you have extra time, consider the best-case time complexity! When does that occur? For credit: Submit some artifact of your work to Moodle, including, at least, the growth function and the time complexity (in Big-Oh) that you found."
  },"/pages/Activity03/": {
    "title": "Activity 03: Sorting 3",
    "keywords": "Activity Sorting",
    "url": "/pages/Activity03/",
    "body": "Learning Goals You will work towards being able to… Formalize algorithmic ideas into pseudocode Prove the correctness of algorithms through induction. Know common algorithms to solve cannonical problems (sorting) Instructions Look back at the pseudocode you’ve written for Activities 1–2 (check your Moodle submissions) Work with your group to prove the correctness of your algorithm. Try and apply the following process: Work through the algorithm to convince yourself that it’s correct, Identify a loop invariant you can use to prove it’s correctness, prove that your pseudocode starts with the invariant being true (the base case of recursion), and finally prove that your pseudocode maintains the loop invariant after every iteration. Note that the above only works for iterative algorithms: proving recursive algorithms correct is even more straightforward! Prove the base case returns the right answer, and show that the recursive step will return the right answer if all of it’s recursive calls return the right answer (which should be true by our inductive assumption! In some cases you may need strong induction!). If you’re having trouble proving your algorithm is correct, try and see if you can identify a counterexample: maybe there’s a case that your algorithm fails on! Try and correct it, if possible! Otherwise, prove incorrectness by demonstrating that your pseudocode won’t correctly sort your counterexample. If you haven’t completed any of the previous sorting activities, take this time to complete them. You should have collected (1) pseudocode for an intuitive sorting algorithm, (2) a big-Oh analysis of it’s time complexity with a proof, and now (3) a proof of correctness! For credit: Submit some artifact of your work to Moodle, including at least an attempt at a proof of correctness"
  },"/pages/Activity04/": {
    "title": "Activity 04: Linear Data Structures Review",
    "keywords": "Activity Sorting",
    "url": "/pages/Activity04/",
    "body": "Learning Goals You will work towards being able to… Understand the time and space complexity properties of Arrays, Stacks, Queues, and Lists Instructions The textbook does a good job reviewing high-level aspects of the linear data structures we’ll be using, but it misses out on some salient details: Namely, the time complexities of basic operations using these data structures. Construct a table that lists the worst-case time complexity of each operation available from a generic Array, Stack, Queue, and List (i.e., consider insert, remove, or look up an element in these collections). Do this using big-$\\Theta$s. You don’t have to provide a proof for each (but if you worry you couldn’t construct one, it might be worth attempting!). Now let’s practice reasoning about algorithms that use these data structures. Consider the following pseudocode StackFunction(String s): Let st be a stack For i &lt;- 1 to length(s): st.push(s[i]) For i &lt;- 1 to length(s): If s[i] != st.pop(): return false return true (one day I’ll figure out a nicer way to format pseudocode here) What does it do? What is this algorithm’s big-$\\Theta$ time complexity? Can you prove it? You don’t know the exact growth functions for the time complexity of the calls to push and pop, but does knowing their big-$\\Theta$ let you reason about StackFunction’s big-$Theta$? For credit: Submit your table from part 1 and your reasoning for part 3."
  },"/pages/Activity05/": {
    "title": "Activity 05: Brute Force Algorithms",
    "keywords": "Activity Design",
    "url": "/pages/Activity05/",
    "body": "Learning Goals You will work towards being able to… Design brute-force algorithms to solve problems. Determine the tiem complexity growth function for pseudocode under the RAM model. Compute big-$O$/$\\Omega$/$\\Theta$s from time complexity growth functions. Convert intuitive algorithmic ideas into pseudocode. Instructions For each of the problem specifications below, try and design a brute-force solution to each. Write out pseudocode for your solution, find the worst-case time complexity (big-$\\Theta$), and convince yourself of correctness. For practice, write out formal proofs (or at least convince yourself you could, if asked!). Substring Match: You’re given Strings $s_1, s_2$ of lengths $n$, $m$ and must return an integer index $i$ such that $s_1[i\\dots i+m-1] = s_2$. For example, with 1-indexing, $s_1$ = E X A M P L E, $s_2$ = A M P means that a algorithm should return $3$. Primality Testing: A prime number is a number $p$ such that $\\forall 2 \\leq k &lt; p$, $p \\mod k \\neq 0$ (that is, no integer between $2$ and $p-1$ evenly divides $p$). A primality testing algorithm takes a natural number $k$ as input and returns true if $k$ is prime and false otherwise. For a example, $7$ is prime (and the algorithm should return true) because $2, 3, 4, 5, 6$ do not divide $7$ evenly, but $6$ is not (and the algorithm should return false) because $2$ and $3$ evenly divide into $6$. Tic-Tac-Toe: Tic-tac-toe is a two player game where players take turns placing markers (x’s or o’s, depending on the player) on a 3x3 grid. A player wins when their marker appears in all squares in a row, column, or diagonal (i.e., 3-in-a-row on a 3x3 grid). If the board is filled and neither player accomplishes this, the game is a draw. Generalize the game to boards of size $k$x$k$, where a player wins when their marker appears $k$ times in a row, column, or diagonal. A tic-tac-toe solver is an algorithm that, given a current board state represented by a $k$x$k$ two-dimensional array and which player moves next, returns 1 if player 1 has a sequence of moves that is guaranteed to win, 2 if player two has such a sequence of moves, or 0 if neither player has such a sequence of moves (i.e., if both players play optimally, the game will end in a draw). HINT 1 This may be a problem where you want to take greater advantage of the flexibility of pseudocode, as there are… well… uninteresting parts of this problem that require a substantial bit of clunky code to write out. Pseudocode will help you avoid this (but thinking about time-complexities won’t let you avoid the complicated bits). For example, don’t worry about how an x, o, or empty square is represented: Just assume you can ask whether a particular square is filled and, if so, which marker it’s filled with! HINT 2 Make sure you consider all of the various branching paths that result from the opposing player’s moves. Can you frame this problem in terms of simpler subproblems of the same type? Maybe your solution should be recursive! Submission Submit pseudocode for your solution to at least 1 or 2, as well as a big-Oh time complexity (you should do at least one runtime analysis + sketch out the proof of correctness, but that won’t be necessary by Wednesday)."
  },"/pages/Activity06/": {
    "title": "Activity 06: Data Structure Review 2",
    "keywords": "Activity DataStructures Review",
    "url": "/pages/Activity06/",
    "body": "Learning Goals You will work towards being able to… Know the time complexities of common implementations of hashtables, priority queues, trees, and graphs Reason about best- and worst-case inputs to these data structures Use the vocabulary of non-linear data structures: hashing/hashcode, loading factor, parent, child, sister/sibling, ancestor/descendent, root, directed/undirected, dense/sparse, connected/connected component, cycle/cyclic/acyclic. Over and above this, the general goal of this assignment is to start getting you to think about these data structures as abstract mathematical objects rather than constructs in programming. Instructions Work with your groups on the problems below. Each section also includes the question marked Bonus, which you should only attempt AFTER solving all of the non-bonus questions in each section. I encourage you to work through these problems with examples. Some of these questions are fairly abstract, and so it may be tempting to work through them entirely abstractly. However, you might find that your intuitions about these abstract structures aren’t great (or worse, wrong!). I recommend that you develop explicit, concrete examples for each of these problems. This may involve working through the problem after picking specific values for unknown constrants (i.e., solve the hashing question with $m=5$ and then with $m=6$! How does changing $m$ change how collisions work out? Can I generalize to all possible $m$?), or explicitly writing out the adjacency list and matrix representations for a few graphs before you get an intuition for which ones are best suited for adjacency matrices vs. lists. Hashing and Maps Suppose you have a hashtable of size $m$ that you use to implement a map with String keys and Integer values. You map keys to indices in the hashtable using the following function: function hash(String s, Integer m): hc &lt;- 0 for i &lt;- 1 to length(s): hc &lt;- hc + letter_num(s[i]) return hc % m Where letter_num returns the position of the letter in the alphabet (i.e., letter_num(“a”) = 1, letter_num(“b”) = 2, …, letter_num(“z”) = 26). For what values of $m$ will the following insertions collide? insert(\"bald\") insert(\"area\") ~~insert(\"sea\")~~ What about the following inserts? insert(\"cheddar\") insert(\"comic\") insert(\"fern\") insert(\"nerf\") Can you conclude anything in-general about your choice of $m$ if you were to implement this hashmap? what $m$ would minimize collisions? What collisions can you not avoid? (If it helps, feel free to make some assumptions: What if the length of string keys have length $\\leq k$, for some $k$? Can you construct a good $m$ in terms of $k$). Feel free to write small pieces of code if it helps you work through the problem! Bonus: For those of you with some probability background, let’s consider the odds of a collision occurring: Suppose you have a hash function $f$ that is distributed uniformly. This means for random $k$ in our space of keys, the corresponding values $f(k)$ are equally likely to be hashed to any of the $m$ slots in our hashtable. Formally, we can say that this means for a sequence of insertions with keys $k_1, \\dots, k_n$, $P(f(k_i) = j) = \\frac{1}{m}$ for any $1 \\leq i \\leq n$ and $1 \\leq j \\leq m$. What is the likelihood of a collision after $n$ insertions (that is, that $\\exists l,m$ such that $f(k_l) = f(k_m)$). Like many probability problems of this type, it might be easier to reason about the likelihood that there aren’t any collisions. PQueues and Heaps Suppose you have a priority queue implemented with a min-heap. Suppose 9 items were successfully inserted into it. What is the structure of the tree? Draw the nodes and parent-child structure. HINT How does a heap maintain balance? What property does the tree underlying the heap always have? Recall that a min-heap has an ordering property such that if node $a$ is a child of node $b$, then $a &gt; b$. Show (formally) that this means that a path from root to leaf $c_1, c_2, \\dots, c_h$ is sorted. For clarity, since $c_1, \\dots c_h$ is a path from root to leaf, this means that for each $1 &lt; i \\leq h$, $c_i$ is the child of $c_{i-1}$. Bonus: When we insert or remove an element from the heap, our algorithm from data structures was to insert it to an incorrect position (i.e., one that violates our ordering property), and then swap it with elements above until it was greater than it’s parent. This is, essentially, a single pass of BubbleSort on the path from the root to the new leaf. Show that this always works! Make sure to use the proper assumptions: What do you know about the structure of the heap before the insert? Write out the pseudocode for the insert and see if you can prove it’s correctness (i.e., that the element is added and that the heap ordering and balance properties are preserved. (Binary Search) Trees Suppose you have an empty (non-self-balancing) binary search tree and insert $k$ elements into it. What is the worst-case time complexity of a look-up for a particular value (in big-$\\Theta$). What does a worst case sequence of insertions look like? (Skiena 3-15) Suppose you want to convert an un-balanced binary search tree to a balanced one. Write an $O(n)$ algorithm that will convert a binary search tree with $n$ nodes to one that is perfectly balanced. Here, take balanced to mean that the depth of any two leaves null pointers (i.e., a missing child) differs by at most 1. HINT Look back at the answer to the hint question in the PQueue/Heap section. Could you borrow a balancing idea from there? BONUS: (Skiena 3-21) Given two BSTs $A$ and $B$ such that $\\forall a \\in A, b \\in B$, $a &lt; b$, write pseudocode to construct a new BST $C$ that contains all of the elements in $A$ and $B$ (that is, $\\forall a \\in A$, $a \\in C$ and $\\forall b \\in B$, $b \\in C$). Do this in $O(h)$ (worst-case) time, where $h$ is the maximum height between $A$ and $B$. &gt; ###### HINT &gt; Focus on ensuring that $C$ satisfies the ordering property for BSTs. Both trees are given to you as ordered BSTs, so try to change the structure of $A$ and $B$ as little as possible when merging them. {: .block-tip} Graphs Construct a graph which will take up less memory as an adjacency list vs. as an adjacency matrix. Consider a complete graph $G = (V, E)$. Being complete means that for any $v_1, v_2 \\in V$, $(v_1, v_2) \\in E$ (every pair of vertices has an edge connecting them). Suppose the graph in undirected. What is $|E|$? That is, how many edges are in $G$? What is the smallest $|E|$ one can have such that $G = (V, E)$ is connected? BONUS: We can think of trees as a special case of graphs. Two equivalent definitions are (1) an undirected graph that is connected and acyclic or (2) a graph where any two vertices are connected by exactly 1 path. Convince yourself (and attempt to show, formally) that (1) these definitions match the way we talk about trees and (2) that these two definitions are equivalent. Submission Upload to Moodle your work on at least one problem per data structure. Convince yourself that you could solve all the problems here independently (with the exception of the bonus problems) to make sure that you’re sufficiently caught up with data structures!"
  },"/pages/Activity07/": {
    "title": "Activity 07: Heap- &amp; TreeSort",
    "keywords": "Activity DataStructures Sorting TreeSort HeapSort",
    "url": "/pages/Activity07/",
    "body": "Learning Goals You will work towards being able to… Build and reason about algorithms that use data structure-based design principles Understanding the core idea of, write pseudocode for, and analyze the runtime and correctness of common algorithms (HeapSort and TreeSort) Understand sorting as a pre-processing step for solving common algorithmic problems. Instructions Work with your groups on the following problems HeapSort Review If you’ve completed the reading response, share and discuss your pseudocode for your heap insert and removemin operations. Hopefully you’ve converged on a $\\log n$ time complexity for each, where $n$ is the size of the heap. Manually step through the operations of a HeapSort call with an array of size 5. You may choose any 5 Integers as the entries of the array. Create some artifact of your work (notes, pictures, etc.) that you can submit to Moodle! Thinking about TreeSort’s Design Write out pseudocode for TreeSort, which works by inserting each element of our array into a Binary Search Tree and filling in a new array by reading out the search tree’s in-order traversal. Skiena had us think about HeapSort as a variant of SelectionSort. While SelectionSort found the minimum unsorted element in our array with a linear search, the key idea (under this view) of HeapSort was that min-heaps provide a more efficient way of repeatedly finding the minimum remaining (unsorted) element. This is the core principle of Data Structure Design: We take a simple, intuitive algorithm and find a data structure (or sometimes construct a bespoke data structure!) to make some of the clunkier operations in the algorithm faster. This principle can also be used to think about TreeSort! Consider the behavior of your TreeSort pseudocode, but for our purposes here, let’s ignore the fact that we need to transform the in-order traversal of nodes into an Array at the end. Simply treat the in-order traversal of the tree as the state of an array. Does this resemble another sorting algorithm you’ve seen? Can you describe TreeSort as a variant of one of those $\\Theta(n^2)$ sorts where a (Self-Balancing) Binary Search Tree improves the efficiency of a part of that algorithm? Bonus: Lets begin analyze TreeSort’s correctness (and runtime, if we didn’t discuss this in lecture!). You’ll find (similar to HeapSort) that the correctness of this algorithm relies on a property of a binary search tree: That it’s in-order traversal is sorted! Use the following definitions: A sequence $a_1, \\dots a_n$ is sorted iff $a_1 \\leq a_2 \\leq \\dots \\leq a_n$. A sequence $a_1, \\dots, a_n$ is an in-order traversal of a binary tree $T$ iff each $a_i$, $1 \\leq i \\leq n$ uniquely maps to the value of a node in $T$ (something, something, a bijection exists for the math majors) and for any $a_i$ and it’s corresponding node $N$, the value of each node in the left subtree of $N$, $a_j$ has index $j &lt; i$ and every element in it’s right subtree of $N$, $a_k$, has index $k &gt; i$. A binary search tree is a tree $T$ such that for every node $N$ with value $m$ in the tree, every value $l$ in the left subtree of $N$ has $l \\leq m$ and for every value $r$ in the right subtree of $N$ has $r \\geq m$. Note that this slightly extends Skiena’s definition, which assumes our trees do not contain duplicates. and write pseudocode for an in-order traversal (recalling it’s recursive structure from 128). Try and show: (1) the pseudocode you wrote is correct, by the definition of an in-order traversal I have given you above, (2) that if this is run on a binary search tree, the in-order traversal must be sorted. Submission Submit an artifact of your work from the HeapSort portion of this assignment, as well as your TreeSort pseudocode."
  },"/pages/Activity08/": {
    "title": "Activity 08: Sorting as Pre-Processing",
    "keywords": "Activity Sorting Design",
    "url": "/pages/Activity08/",
    "body": "Learning Goals You will work towards being able to… Understand sorting as a pre-processing step for solving common algorithmic problems. Turn algorithmic ideas into pseudocode Instructions Work with your groups on the following problems: Sorting for Search: As Skiena tells us, preprocessing an Array with a sorting algorithm lets us use Binary Search instead of Linear Search to find some element. If we only search the array once, is this a good strategy? How many times must we search in order for preprocessing with an $\\Theta(n \\log n)$ sort to be worth it? Make an argument in terms of Big-Oh time complexities. Note that this is a form of amortized analysis! Good-Enough Subset Sum: Given an array $A$ of Integers and an Integer $k$, find a set $S$ that contains the maximum number of elements in $A$ that sum to less than $k$. For example, If you were given $A = [4, 2, 8, -1, 7]$ and $k = 3$, we should find either $S = {2, -1}$ or $S = {4, -1}$. Provide pseudocode for a solution and provide an informal analysis of it’s time complexity. Maximum Gap: Given an array $A$ of Integers, find the pair of Integers $a, b \\in A$, $a &lt; b$ such that (1) there is no $c \\in A$ such that $a &lt; c &lt; b$ and (2) $\\lvert a - b \\rvert$ is maximized. That is, find an element $a$ such that the next largest element in $A$, $b$, is as far away as possible. For example, given $A = [4, 2, 1, 14, -7]$, you should find the pair $(4, 10)$. Again, provide pseudocode and an informal analysis of it’s time complexity. 1 If you have extra time, pick a problem described by Skiena 4.1 and write out it’s pseudocode. Work through an example with your group. Try and see if you can solve it without sorting first! Submission Submit an artifact of your work from any of 1–3. This is a variation on LeetCode problem 164! They ask you to do this in Linear time &amp; space, which isn’t doable with $\\Theta(n \\log n)$ sort preprocessing, unfortunately. However, the idea is still to preprocess with sorting! &#8617;"
  },"/pages/Activity09/": {
    "title": "Activity 09: Quicksort and Partitioning",
    "keywords": "Activity Sorting Quicksort Partitioning",
    "url": "/pages/Activity09/",
    "body": "Learning Goals You will work towards being able to… Understanding the behavior of common algorithms (quicksort) Implement common algorithms (quicksort) Instructions Work with your groups on the following problems: As a group, walk through a few examples of the partitioning algorithm you saw in class/in the reading. Construct a few random arrays and step through the code line-by-line to understand how the array is structured and maintained throughout. Based on our sketch of the proof of correctness for quicksort in lecture, define correctness for the partition algorithm and construct a proof of correctness for the partition algorithm. Feel free to sketch things out (Find the right loop invariant, etc.) while you’re with your group and fill out details on your own. Bonus: This partitioning algorithm isn’t the only (or most efficient, or even first) partitioning algorithm for quicksort. However, this version (called the Lomuto scheme) is generally regarded as a simpler, easier to implement version that doesn’t sacrifice asymptotic time complexity. The other common scheme, the Hoare scheme, is faster, but more complex. It’s also clever in a very intro algorithms sort of way, so it may be worth seeing the trick! partition(A, low, high): pivot &lt;- A[low] i &lt;- low j &lt;- high While True while A[i] &lt; pivot: i &lt;- i + 1 while A[j] &gt; pivot: j &lt;- j - 1 if j &lt;= i: Return j Swap(A[i], A[j]) i &lt;- i + 1 j &lt;- j - 1 Here the idea is to move two indices from the edges toward the center until we find an element on the left that should be on the right and an element on the right that should be on the left. If that happens, we swap them! When the two indices cross, we swap them. Work through a few array with this partition algorithm until you can convince yourself it partitions in a way that can be used to implement quicksort. Note that the pivot isn’t even ending up at the returned index! As a bonus, you can probably find a bug in my pseudocode above. This version is notoriously tricky! Here’s a quote from Jon Bentley’s Programming Pearls: “Most discussions of Quicksort use a partitioning scheme based on two approaching indices… (i.e. Hoare’s). Although the basic idea of that scheme is straightforward, I have always found the details tricky - I once spent the better part of two days chasing down a bug hiding in a short partitioning loop. A reader of a preliminary draft complained that the standard two-index method is in fact simpler than Lomuto’s and sketched some code to make his point; I stopped looking after I found two bugs.” Submission Submit an artifact of your work from 1 and 2."
  },"/pages/Activity10/": {
    "title": "Activity 10: Binary Search Variants",
    "keywords": "Activity Sorting Design",
    "url": "/pages/Activity10/",
    "body": "Learning Goals You will work towards being able to… Understanding the core idea of common algorithms (BinarySearch) Turn algorithmic ideas into pseudocode Apply Divide-and-Conquer design techniques to novel problems Instructions Work with your groups on the following problems: Approximately how wrong: Let’s suppose we want to find a the decimal expansion of a root of a polynomial $f(n)$ to a certain precision. While Skiena tells us that each iteration of binary search gets us closer and closer to the true root, how much closer does each iteration get us? Suppose we have some polynomial $f(x)$ that is guaranteed to have some root $x$ that is between a given $l$ and $r$ (i.e., $\\exists r$, $l \\leq x \\leq r$ such that $f(x) = 0$). Suppose we also have some notion of the precision we desire, $\\varepsilon &gt; 0$, and we want to find some $x’$ such that $x - \\varepsilon \\leq x’ \\leq x + \\varepsilon$. Given all this, how many iterations of the bisection method do we need to call before we can guarantee we can pick such a $x’$? I recommend you first step through the algorithm a few times to get a feel for it’s behavior, and then sketch out a concrete solution for a particular set of choices. Then try and generalize. If you’re confident with that, prove this to be true by constructing a loop invariant! With great power comes great responsibility (with computing resources): Suppose you are a statistician consulting for psychologist. They are worried about statistical power for their upcoming experiment (i.e., they’re concerned that they won’t collect enough data from enough participants to make valid statistical inference). They’ve determined that if they don’t have a statistical power $&gt;0.8$, it’s not worth running the experiment. However, they don’t want to run too many participants, since they have to pay each one, and money is tight. Luckily, you know how to do a power analysis, a computationally intense algorithm that can determine the statistical power given a particular number of subjects. Call the number of subjects $n$. Luckily, you know one helpful fact: the more participants you run, the higher the power you have! What strategy would you use to guarantee the experiment has $&gt;.80$ power, minimize the cost of recruiting participants, and minimize the amount of computational power spent (i.e., minimize the number of power analyses run?).1 Submission Submit an artifact of your work from either 1 or 2. As you might have guessed from the detailed framing and my research area, I did this in some work I did a few years ago, though I was playing both roles. &#8617;"
  },"/pages/Activity11/": {
    "title": "Activity 11: The Master Theorem",
    "keywords": "Activity Sorting Design",
    "url": "/pages/Activity11/",
    "body": "Learning Goals You will work towards being able to… State the definition of the Master Theorem Determine the runtime complexity of recursive functions Use the Master Theorem to understand when a divide and conquer approach results in a faster algorithm Instructions Work with your groups to draw trees that trace the recursive structure of algorithms with the following recurrence relations. For example, for MergeSort, our structure would look something like the below image Each number represents the time complexity of everything but the recursion for that call, and that node’s children represent the recursive calls made from that call. Note that we work out the height of our tree (how many recursions until our problem size is 1?) and the number of leaves in our tree (after all of our recursions, how many branches do we create?). Then observe that the sum of all of these runtimes is our total runtime! As you draw and analyze each tree, pay attention to which terms will dominate the total runtime. Then compare your findings to the master theorem $T(n) = 2T(\\frac{n}{3}) + n^2$ $T(n) = 3T(\\frac{n}{2}) + n$ $T(n) = 4T(\\frac{n}{2}) + n^2$ Submission Submit an artifact of your work from either 1 or 2 or 3."
  },"/pages/Activity12/": {
    "title": "Activity 12: More Divide &amp; Conquer Design",
    "keywords": "Activity DivideAndConquer Design",
    "url": "/pages/Activity12/",
    "body": "Learning Goals You will work towards being able to… Use divide and conquer design principles to write algorithms to solve problems Instructions Work with your groups on the following problems: (LeetCode 198) Suppose you plan to rob houses along a street. 1 However, for safety, you cannot rob adjacent houses, since a strange alarm system will immediately alert the authorities if such an event occurs. You have, however, cased the street well, and have an array $A$ that contains $N$ integers, where $A[i]$ represents the expected illicit earnings from robbing the $i$th house on the street. Write a Divide &amp; Conquer algorithm to determine the maximum profits you can earn without tripping the alarm. Hint Consider whether or not you rob from house $i$. How does this affect the other houses one can take from? Once that decision is made, do you see subproblems that can help you solve the whole thing? (Skiena 5-5) Suppose you have a sorted array of distinct integers $A$. Find a $O(\\log n)$ algorithm find whether there exists some index $i$ such that $A[i] = i$. Hint Remember that the array is sorted and contains integers. This means that $A[i+1] \\geq 1 + A[i]$ for any index $1 \\leq i &lt; N$! Submission Submit an artifact of your work for problem 1 or 2. For the record, COMP221 does not officially endorse any crimes. &#8617;"
  },"/pages/Activity13/": {
    "title": "Activity 13: Graph Traversal",
    "keywords": "Activity Graph DFS BFS",
    "url": "/pages/Activity13/",
    "body": "Learning Goals You will work towards being able to… Familiarize yourself with common algorithms (Depth \\&amp; Breadth First Search) Translate problem specifications into graph problems to be solved with standard algorithms. Warm-Up: Two-Tabled Wedding (Skiena 7-15): You are organizing seating for a wedding where all guests in a list $V$ must be organized into two tables. You also have a list $E$ of pairs of people who hate each other. Discuss how you might, if possible, construct a table assignment that avoids any enemies being at the same table. What kind of a graph problem is this? Instructions Work with your groups on the following problems. You may work on them in any order: Articulate a Plan Let’s dig a bit further into finding articulation points (sometimes called cut-vertices) in a graph. Draw a DFS tree starting at A, and annotate that tree with (1) the depth of each node within the tree, (2) dashed lines for the backward edges, and finally (3) the smallest depth of the node or non-parent neighbors of that node (i.e. backward edges or the depth of the node itself). Call this 3rd value the 1-step high-point of the vertex. 1 What do you notice about the 1-step high-points of children of articulation vertices (identify the articulation vertices visually at first, then look at the 1-step high-points of their children)? Their descendents? See if you can generalize: Is there a new value at each vertex you should actually keep track of? Compare these to the conditions of of being an articulation vertex outlined in Skiena (how does the measure you want to construct relate to Skiena’s reachable vertices?). Then write out pseudocode for this specific articulation vertex finding algorithm (not the genericized version Skiena gives you to demonstrate that it’s a variant of BFS!) Covering for a Friend (Skiena 7-18) A Vertex Cover for a graph $G = (V, E)$ is a set $V’ \\subset V$ (a subset of $V$ such that ever edge is incident to some $v \\in V’$ (formally, $\\forall (v_1, v_2) \\in E$, either $v_1 \\in V’$ or $v_2 \\in V’$). Informally, this just means for every edge, at least one vertex on the end of that edge is in $V’$. Suppose you have $\\lvert V \\rvert$ people working on $\\lvert E \\rvert$ projects in teams of 2. You want to organize a meeting where at least one person on each project is present to talk about progress on that project. This is a vertex cover problem — identify the vertices and edges of the implicit graph and convince yourself the solution is a vertex cover! Skiena 7-18 suggests one algorithm for finding a vertex cover is building a DFS tree and pruning the leaves. Prove, given what you know about edges in a DFS tree, that this is always a vertex cover. Note that by Skiena’s definition, we disallow self-edges in our graphs! If you’re having trouble, ask for a hint! Submission Submit an artifact of your work for one of the two problems. I would add a bit of flavor to this problem (perhaps something about oil pipelines or critical telecommunications infrastructure), but I really need to be clear that COMP221 does not officially endorse any crimes. &#8617;"
  },"/pages/Activity14/": {
    "title": "Activity 14: Minimum Spanning Trees and Prim’s Algorithm",
    "keywords": "Activity MST graph Prims greedy",
    "url": "/pages/Activity14/",
    "body": "Learning Goals You will work towards being able to… Be familiar with canonical algorithms (Prim’s, Kruskal’s) Translate problems into graph problems and solve them with cannonical graph algorithms (MST Problems) Design and prove correct/incorrect algorithms based on Greedy design principles. Warm-Up Recall from the reading that a Spanning Tree $T = (V’, E’)$ of a graph $G = (V, E)$ spans the graph $G$ (i.e., $V’ = V$) and is a tree (T is acyclic and connected). Suppose you had a spanning tree and added a new edge $e \\in E \\setminus E’$, constructing $T’ = (V, E’ \\cup \\{ e \\} )$. Does $T’$ contain a cycle? Convince your table-mates! As a bonus: How many edges must be in an MST? How do these two results interact? Activity (Skiena 8-2) Since a Minimum Spanning Tree is connected, that means for any vertices $s, t \\in V$, there is a path in the minimum spanning tree between them (i.e., by our in-class definitions, a sequence of edges $(s, v_1), (v_1, v_2) \\dots (v_{k-1}, t) \\in E’$). Is this path the shortest path in $G$ between those vertices? Check intuitions between people at your table. Come to a consensus, and then either prove it true, or construct a graph that presents a counterexample! (Skiena 8-8a) Suppose you construct an MST $T$ for a weighted graph $G$. Then you construct a graph $G’$ where the weight of each graph is increased by exactly $k$. Does the MST necessarily contain the same edges? Convince yourself and this table that this is true! (Skiena 8-8b) Suppose you have a shortest path from $s \\in V$ to $t \\in V$ in $G$. Using the $G’$ construction from the previous problem, does the shortest path in $G’$ always contain the same edges as the shortest path in $G$? Submission Submit an artifact of your work for problem 1, or 2 &amp; 3. As a hint, all 3 rely on the same essential intuition!"
  },"/pages/Activity15/": {
    "title": "Activity 15: Shortest Paths and Dijkstra’s Algorithm",
    "keywords": "Activity Shortest Path Dijkstra",
    "url": "/pages/Activity15/",
    "body": "Learning Goals You will work towards being able to… Recall the core principles behind canonical algorithms (Prim’s, Kruskal’s, Dijkstra’s) Prove the (in)correctness of algorithmic techniques. Activity Prove that Dijkstra’s algorithm is not correct for all graphs with negative weights. Do this by constructing a counterexample: Draw me a graph with negative edge weights and show that Dijkstra’s algorithm returns the incorrect shortest path. Step through the pseudocode for Dijkstra’s on the following Graph, representing Dutch cities and the rough travel time between them in minutes. Start by computing a shortest path tree rooted at Amsterdam (Run Dijkstra’s without a target node, running it until you run out of paths to consider in the PQueue). Then try running Kruskal’s and Prim’s to get a MST. Submission It’s Spring Break, don’t worry about it"
  },"/pages/Activity16/": {
    "title": "Activity 16: Max-Flow and Ford-Fulkerson",
    "keywords": "Activity max flow min cut ford-fulkerson",
    "url": "/pages/Activity16/",
    "body": "Learning Goals You will work towards being able to… Familiarize youself with canonical algorithms (Ford-Fulkerson/Edmonds-Karp) Prove the (in)correctness of algorithmic techniques. Activity Part 1 Today, Let’s walk through the development of a max-flow algorithm using the Ford-Fulkerson method! First, we’ll note that the pseudocode provided in class for Ford-Fulkerson is underspecified: write out the steps of the pseudocode in a more concrete manner. Arrive at consensus with your tablemates about how you might find an augmenting path (the tricky part of the implementation)! Note that we’ll also know when $s$ and $t$ are disconnected when this path finding algorithm fails to find a path, which will allow us to set our termination condition for our while loop! HINT Observe that an edge $e$ is only in the residual graph $G_r$ iff the remaining capacity $c(e) - f(e) &gt; 0$. Note that we should be able to do this in (graph) linear time ($O(\\lvert V \\rvert + \\lvert E \\rvert)$). Now we need to figure out that a Ford-Fulkerson implementation is correct. In order to do that, we need to first determine that the flows that we compute are real flows. That is, they satisfy the four properties of flows: that the flow through an edge respects the capacity of the edge ($f(e) \\leq c(e)$ for all $e \\in E$), that flow values are symmetric $f((v_1, v_2)) = -f((v_2, v_2))$, that the in-flow and out-flow at each vertex are equal ($\\sum_{(v, w) \\in E} f((v,w)) = \\sum_{(w, v) \\in E} f((w,v))$ for all non-source or target vertices), and that the flow out of $s$ matches the flow into $t$ ($\\sum_{(s, v) \\in E} f((s,v)) = \\sum{(v, t) \\in E} f((v,t))$). For each of these, briefly convince yourself that these properties are (1) true before the while loop begins and (2) are maintained for every iteration (i.e., are loop invariants!). Convince yourselves that you could prove this, if asked! To finish a proof of correctness, we need to prove that flow if minimal. Of course, we need to compute the flow value in the first place! I left that out! How would you compute the max-flow given the structure of the algorithm (i.e., what do you return?)? Once you have that, how would you argue for this value being the cost of the minimum cut between $s$ and $t$? Since we have a result that tells us that the maximum-flow is the minimum cut, this is what’s left to show! Now let’s think about the time complexity of this algorithm: What is the time complexity of everything inside the while-loop? Now suppose all of our costs are integers ($c:E \\to \\mathbb{Z}$) and our max flow is some value $F$. How many iterations can the while loop run? Given that, what’s the runtime of this algorithm?1 HINT Every time we find an augmenting path, what is the minimum amount the flow we compute must increase? Submission Submit an artifact of your work on Moodle. If you use a particular algorithm to find augmenting paths, you can prove that this algorithm runs in $\\Theta(\\lvert V \\rvert \\lvert E \\rvert^2)$ time even for real-valued capacities. This particular implementation is called the Edmonds-Karp algorithm. &#8617;"
  },"/pages/Activity17/": {
    "title": "Activity 17: APSP and Floyd-Warshall",
    "keywords": "Activity apsp all path shortest floyd warshall",
    "url": "/pages/Activity17/",
    "body": "Learning Goals You will work towards being able to… Familiarize youself with canonical algorithms (Floyd-Warshall) Activity Step through Floyd-Warshall to find the shortest paths between the Dutch cities using the graph below. You should maintain a table that keeps track of the shortest distance between each pair of cities for all of the currently allowed intermediate vertices, updating all of the entries at each iteration. In the implementation of Floyd-Warshall I showed you, and in the example above, I mentioned that we only need to maintain a single $\\lvert V \\rvert$ x $\\lvert V \\rvert$ table of shortest paths so far. However, in the update equation I gave you, $SP(s, t, V’ \\cup \\{ w \\} ) = \\min(SP(s, t, V’), SP(s, w, V’) + SP(w, t, V’))$, the elements of the table on the left-hand side of the equation correspond to an updated form of the table and the elements on the right-hand side correspond to an older version of the table (before $w$ was allowed to be an intermediate vertex!). Is this problematic? That is, is it okay that the SPs on the right hand side of the update equation could have possibly had their entries updated already? Like Dijkstra’s, Floyd-Warshall runs into issues with negative edge weights, but is slightly more robust to them: Floyd-Warshall only fails when there is a negative cost cycle in $G$ w.r.t. $c$. Construct a graph with such a cycle and run Floyd-Warshall. Can you think of a stategy to find negative weight cycles in a graph using Floyd-Warshall? Hint What is the cost of the shortest path from $v$ to $v$ for any vertex $v \\in V$ if there is a negative weight cycle? Submission Submit an artifact of your work on Moodle."
  },"/pages/Activity18/": {
    "title": "Activity 18: Dynamic Programming Practice",
    "keywords": "Activity dynamic programming dp",
    "url": "/pages/Activity18/",
    "body": "Learning Goals You will work towards being able to… Design dynamic programming solutions to algorithmic problems Activity For each of the following questions, design a recurrence relation, and then provide pseudocode for a dynamic programming algorithm to solve it. Consider the time and space complexity of your solutions. It may be helpful to play around with the problem specification to build intution (i.e., work through an example!) before jumping to designing an algorithm. (Skiena 10-1) A child running up a staircase can hop between 1 and $k$ steps at a time. Suppose the staircase is $n$ steps tall. How many unique ways can the child climb the staircase? If you prefer a more math-y framing, how many unique sequences of integers $s_1, s_2, \\dots, s_l$, where $\\forall 1 \\leq i \\leq l, 1 \\leq s_i \\leq k$ exist such that $\\sum s_i = n$? (Skiena 10-5) Consider an $s$ x $t$ grid $G$ filled with non-negative numbers. Find a “path” from the top left to bottom right corner than minimizes the sum of numbers along the path. That is, you start at the top-left corner, and at each step can choose to move down within the same column or right within the same row. Submission Submit an artifact of your work on Moodle."
  },"/pages/Activity19/": {
    "title": "Activity 19: Dynamic Programming Practice 2",
    "keywords": "Activity dynamic programming dp",
    "url": "/pages/Activity19/",
    "body": "Learning Goals You will work towards being able to… Design dynamic programming solutions to algorithmic problems Activity For each of the following questions, design a recurrence relation, and then provide pseudocode for a dynamic programming algorithm to solve it. Consider the time and space complexity of your solutions. It may be helpful to play around with the problem specification to build intution (i.e., work through an example!) before jumping to designing an algorithm. Day 1 Write out pseudocode for the edit distance algorithm we discussed in lecture. Day 2 Write out pseudocode for the CKY Parsing distance algorithm we discussed in lecture. Days 1–3 (Skiena 10-6) Modify the edit distance algorithm we’ve discussed to allow for transposition errors, where at the cost of one operation, you can swap two adjacent characters. Convince yourself that your recurrence works, and run your pseudocode on the “steve”/”setve” pair Skiena gives you. (Skiena 10-7) Suppose you have 3 strings, $x, y, z$, where $\\lvert z \\rvert = \\lvert x \\rvert + \\lvert y \\rvert$. $z$ is a shuffle of $x$ and $y$ if it interleaves characters from $x$ and $y$ preserving their order. That is, you take $x$ and insert all characters of $y$ into the string such that the order of characters in $y$ are preserved. See Skiena 10-7a for examples — confirm that they make sense! Then write a dynamic programming algorithm (based on the structure of edit distance!) that determines whether $z$ is a shuffle of $x$ and $y$. (Skiena 10-23) In some programming languages, the cost of spliting a string of length $n$ into two pieces is $\\Theta(n)$. This happens in languages where strings are immutable, and thus must be copied for string operations like this! For simplicity, let’s assume it actually takes exactly $n$ time steps. Suppose you want to make a sequence of splits such that the original string $s$ ends up split at positions $P = {p_1, p_2, \\dots, p_k}$. That is, we want to conduct a series of splits such that we end up with $s[0\\dots p_1], s[p_1+1, \\dots p_2], \\dots, s[p_k+1\\dots n]$. What order of splits will get you those splits the fastest? Design an $\\Theta(n^3)$ algorithm to find the minimum cost of splitting the strings in this way. For example, if $P = [3, 8, 10]$ and $n=20$, Splitting first at 3 takes 20 time steps, then at 8 takes 17, and finally at 10 takes 12, resulting in 49 time steps! Going in the reverse order, splitting at 10 takes 20, then at 8 takes 10, and finally at 3 takes 8, totalling 38. Hint Think back to CKY Parsing! Submission Submit an artifact of your work on Moodle."
  },"/pages/Activity20/": {
    "title": "Activity 20: Complexity Theory and Hardness Reductions",
    "keywords": "Activity complexity theory hardnesss reduction",
    "url": "/pages/Activity20/",
    "body": "Learning Goals You will work towards being able to… Design reductions to prove the hardness of problems Activity Work with your groups to work through the following problems. For these in particular, discuss at your tables to make sure everyone comes to agreement! Day 1 Suppose a problem $X$ is tractable, and you have an algorithm that runs in polynomial time that turns a solution from problem $X$ into a solution for problem $Y$. Can you tell if Problem $Y$ is tractable? If so, is it? Suppose a problem $X$ is intractable, and you have an algorithm that runs in polynomial time that turns a solution from problem $X$ into a solution for problem $Y$. Can you tell if Problem $Y$ is tractable? If so, is it? Suppose a problem $Y$ is intractable, and you have an algorithm that runs in polynomial time that turns a solution from problem $X$ into a solution for problem $Y$. Can you tell if Problem $X$ is tractable? If so, is it? Suppose a problem $Y$ is tractable, and you have an algorithm that runs in polynomial time that turns a solution from problem $X$ into a solution for problem $Y$. Can you tell if Problem $X$ is tractable? If so, is it? Raise your hand and check your answers to each of these questions! Day 2 (Skiena 11-4) Stingy SAT is a problem that that asks, given a set of clauses (that is, disjunctions of literals) and $k \\in \\mathbb{Z}_{\\geq 0}$, determine whether there is an assignment of boolean values to variables such that each clause evaluates to true and at most $k$ of the variables are assigned to true. Prove that this is NP-hard! Hint Reduce this from an instance of the SAT problem!1 (Skiena 11-10) The (Minimum) Set Cover problem provides you a set $X$, a set of subsets of $X$ called $F$, and asks you to find the smallest subset of $F’ \\subseteq F$ such that $X \\subseteq \\bigcup_{S \\in F’} S$. That is, select the fewest number of subsets from $F$ such that the union of those subsets contains every element in $X$. A Set-Cover decision problem asks, for $F$, $X$, and $k \\in \\mathbb{Z}_{\\geq 0}$ if there exists $F’ \\subseteq F$ that is a set cover w.r.t. $X$ and $\\lvert F’ \\rvert \\leq k$. Working with the decision problems, Assuming Vertex Cover is NP-Hard, prove Set Cover is NP-Hard via a reduction. Provide a verification algorithm for Set Cover. That is, given a potential solution to the set cover problem, provide an algorithm to verify it. Show that this verification can be done in polynomial time (i.e., Set Cover is NP-Complete). Day 3 Recall that a clique in a graph $G=(V, E)$ is a set of vertices $C \\subseteq V$ such that every $v, w \\in C$ are connected (i.e., $(v,w) \\in E$). The clique decision problem asks, given a graph $G = (V, E)$ and $k \\in \\mathbb{Z}_{\\geq 0}$, if a clique of size $\\geq k$ exists in $G$. Suppose you consider a simplified version of the problem where you’re guaranteed that $G$ only contains vertices with degree $\\leq k$. Prove that this problem is tractable (i.e., find a polynomial-time solution). Submission Submit an artifact of your work on Moodle. The reductions we’ve looked at thus far are called Turing (or sometimes Cook) reductions. A more restricted class or reductions that require that you can translate the inputs of Problem Y into inputs of Problem X such that the solution to that problem instance for problem X is also the solution to the original instance of Problem Y is called a Karp or Many-One reduction. That is, you can find a function that maps inputs for Problem Y into inputs for Problem X that have the same solution. Given how restricted Karp reductions are, they are more powerful than Turing reductions, and are the standard kind of reduction in complexity theory. &#8617;"
  }}
